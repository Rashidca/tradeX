{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjqcKKXL9fzR",
        "outputId": "e7dcb6e4-e58a-49fb-8c37-1b3d3b6305c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "exWb7tGJ9bG6",
        "outputId": "7e5b203d-9eeb-45ca-d08c-5da090778011"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv (Python 3.12.10)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/afrahanas/Downloads/project3/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "from prophet import Prophet\n",
        "from prophet.diagnostics import cross_validation, performance_metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load and prepare the data (using the uploaded file name)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AAPL_all_data2.csv\", header=0, skiprows=[1, 2])\n",
        "df.rename(columns={'Price': 'Date'}, inplace=True)\n",
        "df_prophet = df[['Date', 'Close']].rename(columns={'Date': 'ds', 'Close': 'y'})\n",
        "df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
        "\n",
        "# 2. Split into final training and holdout test sets\n",
        "# This remains the same: we hold out the last year for our final, unbiased evaluation.\n",
        "split_date = df_prophet['ds'].max() - pd.DateOffset(days=365)\n",
        "train_df = df_prophet[df_prophet['ds'] <= split_date]\n",
        "test_df = df_prophet[df_prophet['ds'] > split_date]\n",
        "\n",
        "print(f\"Training data goes up to {train_df['ds'].max()}\")\n",
        "print(f\"Testing data starts from {test_df['ds'].min()}\\n\")\n",
        "\n",
        "\n",
        "# --- NEW: Hyperparameter Tuning using Cross-Validation ---\n",
        "# We define a grid of parameters to test. This will find the best model configuration.\n",
        "grid = {\n",
        "    'changepoint_prior_scale': [0.001, 0.05, 0.1, 0.5],\n",
        "    'seasonality_prior_scale': [1.0, 5.0, 10.0],\n",
        "    'seasonality_mode': ['additive', 'multiplicative']\n",
        "}\n",
        "\n",
        "all_params = [dict(zip(grid.keys(), v)) for v in itertools.product(*grid.values())]\n",
        "rmses = []  # Store the RMSEs for each parameter combination\n",
        "\n",
        "print(f\"Starting hyperparameter tuning with {len(all_params)} combinations...\")\n",
        "\n",
        "# We perform cross-validation on the TRAINING data to find the best params\n",
        "for params in all_params:\n",
        "    m = Prophet(**params).fit(train_df)\n",
        "    # Use cross-validation settings appropriate for daily data with a yearly horizon\n",
        "    df_cv = cross_validation(m, initial='730 days', period='180 days', horizon='365 days', parallel=\"processes\")\n",
        "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
        "    rmses.append(df_p['rmse'].values[0])\n",
        "\n",
        "# Find the best parameters based on the lowest RMSE\n",
        "tuning_results = pd.DataFrame(all_params)\n",
        "tuning_results['rmse'] = rmses\n",
        "tuning_results = tuning_results.sort_values('rmse')\n",
        "best_params = tuning_results.iloc[0].to_dict()\n",
        "\n",
        "print(\"\\n--- Best Hyperparameters Found ---\")\n",
        "print(best_params)\n",
        "\n",
        "\n",
        "# --- FIX: The best_params dictionary contains the 'rmse' metric, which is not a Prophet parameter.\n",
        "# We must remove it before creating the final model.\n",
        "best_params.pop('rmse')\n",
        "\n",
        "\n",
        "# 3. Fit the FINAL model with the best parameters and evaluate\n",
        "print(\"\\nFitting final model with best parameters...\")\n",
        "final_model = Prophet(**best_params)\n",
        "final_model.fit(train_df)\n",
        "\n",
        "# Make predictions on the holdout test set\n",
        "future_test = test_df[['ds']]\n",
        "forecast = final_model.predict(future_test)\n",
        "\n",
        "# 4. Calculate Final Accuracy Metrics\n",
        "results_df = pd.merge(test_df, forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds')\n",
        "\n",
        "mae = mean_absolute_error(results_df['y'], results_df['yhat'])\n",
        "rmse = np.sqrt(mean_squared_error(results_df['y'], results_df['yhat']))\n",
        "mape = mean_absolute_percentage_error(results_df['y'], results_df['yhat'])\n",
        "\n",
        "print(\"\\n--- Final Accuracy Metrics on Test Set (with Tuned Model) ---\")\n",
        "print(f'Mean Absolute Error (MAE): ${mae:.2f}')\n",
        "print(f'Root Mean Squared Error (RMSE): ${rmse:.2f}')\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mape:.2%}')\n",
        "\n",
        "\n",
        "# 5. Visualize the final results (same as before)\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(results_df['ds'], results_df['y'], label='Actual Price', color='blue')\n",
        "plt.plot(results_df['ds'], results_df['yhat'], label='Predicted Price (Tuned)', color='red', linestyle='--')\n",
        "plt.fill_between(results_df['ds'], results_df['yhat_lower'], results_df['yhat_upper'], color='red', alpha=0.2, label='Uncertainty Interval')\n",
        "plt.title('Tuned Stock Price Forecast vs. Actuals (Test Set)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
